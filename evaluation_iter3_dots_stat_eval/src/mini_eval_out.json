{
  "metrics_agg": {
    "n_test_examples": 40,
    "n_total_examples": 200,
    "dots_k5_test_accuracy": 0.725,
    "figs_aa_test_accuracy": 0.75,
    "accuracy_gap_method_vs_baseline": -0.025,
    "acc_figs_axis_aligned": 0.75,
    "acc_figs_oblique": 0.775,
    "acc_dots_K2": 0.725,
    "acc_dots_K3": 0.725,
    "acc_dots_K4": 0.725,
    "acc_dots_K5": 0.725,
    "acc_dots_K6": 0.725,
    "acc_dots_K8": 0.725,
    "acc_dots_K10": 0.725,
    "acc_random_forest": 0.75,
    "acc_decision_tree": 0.725,
    "acc_logistic_regression": 0.625,
    "mcnemar_p_value": 1.0,
    "mcnemar_odds_ratio": 0.75,
    "k_sweep_range": 0.0,
    "k_sweep_cv": 0.0,
    "k_sweep_spearman_rho": 0.0,
    "stability_mean_cosine": 0.746988,
    "stability_null_mean": 0.12061,
    "stability_z_score": 6.9968,
    "stability_uplift_ratio": 6.1934,
    "k2_dominates_all": 1,
    "verdict_score": 4,
    "criteria_met": 1,
    "criteria_partial": 2,
    "criteria_not_met": 2,
    "criteria_triggered": 1,
    "dots_k5_ci_lower": 0.575,
    "dots_k5_ci_upper": 0.85,
    "dots_k5_boot_se": 0.069894,
    "figs_aa_ci_lower": 0.6,
    "figs_aa_ci_upper": 0.875
  },
  "examples": [
    {
      "input": "Classify the following tabular data sample:\n  F1R: 70.5115\n  F1S: 68.6717\n  F2R: 73.4257\n  F2S: 70.9376\n  F3R: 69.8081\n  F3S: 75.5893\n  F4R: 74.3434\n  F4S: 74.9221\n  F5R: 62.4270\n  F5S: 58.7198\n  F6R: 74.2912\n  F6S: 68.1433\n  F7R: 72.1623\n  F7S: 71.7832\n  F8R: 65.8924\n  F8S: 61.4556\n  F9R: 63.9251\n  F9S: 68.2745\n  F10R: 62.5670\n  F10S: 69.5379\n  F11R: 75.7197\n  F11S: 73.4661\n  F12R: 67.9053\n  F12S: 67.6491\n  F13R: 74.2484\n  F13S: 74.9687\n  F14R: 77.8881\n  F14S: 58.0411\n  F15R: 66.7277\n  F15S: 56.8563\n  F16R: 72.4846\n  F16S: 70.6133\n  F17R: 61.0524\n  F17S: 62.3341\n  F18R: 70.6179\n  F18S: 73.2205\n  F19R: 66.2160\n  F19S: 67.0068\n  F20R: 71.3128\n  F20S: 64.1250\n  F21R: 72.6112\n  F21S: 55.5439\n  F22R: 56.0531\n  F22S: 62.4607",
      "output": "1",
      "context": {
        "features": {
          "F1R": 70.511505,
          "F1S": 68.671743,
          "F2R": 73.425668,
          "F2S": 70.937631,
          "F3R": 69.808125,
          "F3S": 75.589292,
          "F4R": 74.343356,
          "F4S": 74.922059,
          "F5R": 62.426992,
          "F5S": 58.719846,
          "F6R": 74.291185,
          "F6S": 68.143263,
          "F7R": 72.162324,
          "F7S": 71.783171,
          "F8R": 65.89236,
          "F8S": 61.455557,
          "F9R": 63.925101,
          "F9S": 68.274493,
          "F10R": 62.567038,
          "F10S": 69.537886,
          "F11R": 75.719678,
          "F11S": 73.466135,
          "F12R": 67.905253,
          "F12S": 67.649116,
          "F13R": 74.248354,
          "F13S": 74.968661,
          "F14R": 77.888084,
          "F14S": 58.041097,
          "F15R": 66.727746,
          "F15S": 56.856327,
          "F16R": 72.484556,
          "F16S": 70.613295,
          "F17R": 61.052396,
          "F17S": 62.334105,
          "F18R": 70.617884,
          "F18S": 73.220532,
          "F19R": 66.216008,
          "F19S": 67.006762,
          "F20R": 71.312786,
          "F20S": 64.124958,
          "F21R": 72.611237,
          "F21S": 55.54386,
          "F22R": 56.053076,
          "F22S": 62.460724
        },
        "n_features": 44,
        "task_type": "binary_classification",
        "dataset_source": "OpenML-797 benchmark suite",
        "feature_type": "numeric",
        "preprocessing": "none_needed_already_numeric",
        "evaluation_results": {
          "family1_bootstrap_ci": {
            "dots_K5": {
              "accuracy": {
                "point": 0.725,
                "mean": 0.724617,
                "se": 0.069894,
                "ci_lower": 0.575,
                "ci_upper": 0.85
              }
            },
            "figs_axis_aligned": {
              "accuracy": {
                "point": 0.75,
                "mean": 0.749978,
                "se": 0.068995,
                "ci_lower": 0.6,
                "ci_upper": 0.875
              }
            },
            "figs_oblique": {
              "accuracy": {
                "point": 0.775,
                "mean": 0.775,
                "se": 0.066026,
                "ci_lower": 0.64559,
                "ci_upper": 0.90441
              }
            },
            "dots_K2": {
              "accuracy": {
                "point": 0.725,
                "mean": 0.725,
                "se": 0.0706,
                "ci_lower": 0.586624,
                "ci_upper": 0.863376
              }
            },
            "dots_K3": {
              "accuracy": {
                "point": 0.725,
                "mean": 0.725,
                "se": 0.0706,
                "ci_lower": 0.586624,
                "ci_upper": 0.863376
              }
            },
            "dots_K4": {
              "accuracy": {
                "point": 0.725,
                "mean": 0.725,
                "se": 0.0706,
                "ci_lower": 0.586624,
                "ci_upper": 0.863376
              }
            },
            "dots_K6": {
              "accuracy": {
                "point": 0.725,
                "mean": 0.725,
                "se": 0.0706,
                "ci_lower": 0.586624,
                "ci_upper": 0.863376
              }
            },
            "dots_K8": {
              "accuracy": {
                "point": 0.725,
                "mean": 0.725,
                "se": 0.0706,
                "ci_lower": 0.586624,
                "ci_upper": 0.863376
              }
            },
            "dots_K10": {
              "accuracy": {
                "point": 0.725,
                "mean": 0.725,
                "se": 0.0706,
                "ci_lower": 0.586624,
                "ci_upper": 0.863376
              }
            },
            "random_forest": {
              "accuracy": {
                "point": 0.75,
                "mean": 0.75,
                "se": 0.068465,
                "ci_lower": 0.615808,
                "ci_upper": 0.884192
              }
            },
            "decision_tree": {
              "accuracy": {
                "point": 0.725,
                "mean": 0.725,
                "se": 0.0706,
                "ci_lower": 0.586624,
                "ci_upper": 0.863376
              }
            },
            "logistic_regression": {
              "accuracy": {
                "point": 0.625,
                "mean": 0.625,
                "se": 0.076547,
                "ci_lower": 0.474969,
                "ci_upper": 0.775031
              }
            }
          },
          "family2_mcnemar": [
            {
              "table": [
                [
                  26,
                  3
                ],
                [
                  4,
                  7
                ]
              ],
              "chi2": null,
              "p_value": 1.0,
              "odds_ratio": 0.75,
              "test_type": "exact_binomial",
              "method_a": "dots_K5",
              "method_b": "figs_axis_aligned",
              "significant_at_005": false,
              "significant_at_010": false,
              "p_adjusted": 1.0
            }
          ],
          "family3_k_sweep": {
            "k_values": [
              10,
              2,
              3,
              4,
              5,
              6,
              8
            ],
            "accuracies": [
              0.725,
              0.725,
              0.725,
              0.725,
              0.725,
              0.725,
              0.725
            ],
            "range": 0.0,
            "cv": 0.0,
            "mean": 0.725,
            "std": 0.0,
            "spearman_rho": 0.0,
            "spearman_p": 1.0,
            "slope": 0.0,
            "r_squared": 0.0,
            "slope_p": 1.0,
            "kappa_vs_k2": {
              "K10": 1.0,
              "K3": 1.0,
              "K4": 1.0,
              "K5": 1.0,
              "K6": 1.0,
              "K8": 1.0
            },
            "nmi_k_correctness": 0.0,
            "flatness_classification": "flat",
            "interpretation": "All DOTS K values produce identical test accuracy (0.725). The K-sweep is perfectly flat with zero variance. This means the dictionary size constraint has NO effect on predictive accuracy — K=2 is sufficient and adding more directions provides no accuracy benefit."
          },
          "family4_stability": {
            "observed_pairwise_similarities": [
              0.694568,
              0.639089,
              0.843655,
              0.830646,
              0.89992,
              0.644888,
              0.729034,
              0.676075,
              0.775957,
              0.917113,
              0.70384,
              0.751033,
              0.667515,
              0.677716,
              0.708641,
              0.784495,
              0.709519,
              0.747933,
              0.703827,
              0.834296
            ],
            "observed_mean": 0.746988,
            "observed_std": 0.079511,
            "null_analytical_mean": 0.121676,
            "null_simulated_mean": 0.12061,
            "null_simulated_std": 0.089524,
            "null_matched_dict": {
              "K3": {
                "mean": 0.179212,
                "std": 0.04671
              },
              "K5": {
                "mean": 0.21257,
                "std": 0.034073
              }
            },
            "z_score": 6.9968,
            "p_value": 0.0,
            "stability_uplift_ratio": 6.1934,
            "per_k_results": {
              "K3": {
                "mean_cosine": 0.765095,
                "n_pairs": 10,
                "min_sim": 0.639089,
                "max_sim": 0.917113,
                "fold_accuracies": [
                  0.75,
                  0.75,
                  0.75,
                  0.71875,
                  0.71875
                ]
              },
              "K5": {
                "mean_cosine": 0.728881,
                "n_pairs": 10,
                "min_sim": 0.667515,
                "max_sim": 0.834296,
                "fold_accuracies": [
                  0.75,
                  0.75,
                  0.75,
                  0.71875,
                  0.71875
                ]
              }
            },
            "per_k_z_scores": {
              "K3": {
                "z_score": 12.543,
                "p_value": 0.0,
                "null_mean": 0.179212
              },
              "K5": {
                "z_score": 15.1531,
                "p_value": 0.0,
                "null_mean": 0.21257
              }
            },
            "conclusion": "Dictionary stability (0.747) is 6.2x the null expectation (0.121), z=7.0, p<1.3e-12. The learned directions capture genuine data structure, not random noise."
          },
          "family5_pareto": {
            "all_configs": [
              {
                "method": "dots_K2",
                "K": 2,
                "accuracy": 0.725,
                "n_splits": 15
              },
              {
                "method": "dots_K3",
                "K": 3,
                "accuracy": 0.725,
                "n_splits": 15
              },
              {
                "method": "dots_K4",
                "K": 4,
                "accuracy": 0.725,
                "n_splits": 15
              },
              {
                "method": "dots_K5",
                "K": 5,
                "accuracy": 0.725,
                "n_splits": 15
              },
              {
                "method": "dots_K6",
                "K": 6,
                "accuracy": 0.725,
                "n_splits": 15
              },
              {
                "method": "dots_K8",
                "K": 8,
                "accuracy": 0.725,
                "n_splits": 15
              },
              {
                "method": "dots_K10",
                "K": 10,
                "accuracy": 0.725,
                "n_splits": 15
              },
              {
                "method": "figs_axis_aligned",
                "K": 44,
                "accuracy": 0.75,
                "n_splits": 0
              },
              {
                "method": "figs_oblique",
                "K": 44,
                "accuracy": 0.775,
                "n_splits": 0
              },
              {
                "method": "random_forest",
                "K": 44,
                "accuracy": 0.75,
                "n_splits": 0
              }
            ],
            "pareto_front": [
              {
                "method": "dots_K2",
                "K": 2,
                "accuracy": 0.725,
                "n_splits": 15
              },
              {
                "method": "figs_oblique",
                "K": 44,
                "accuracy": 0.775,
                "n_splits": 0
              }
            ],
            "dominated_configs": [
              {
                "method": "dots_K3",
                "K": 3,
                "accuracy": 0.725,
                "n_splits": 15
              },
              {
                "method": "dots_K4",
                "K": 4,
                "accuracy": 0.725,
                "n_splits": 15
              },
              {
                "method": "dots_K5",
                "K": 5,
                "accuracy": 0.725,
                "n_splits": 15
              },
              {
                "method": "dots_K6",
                "K": 6,
                "accuracy": 0.725,
                "n_splits": 15
              },
              {
                "method": "dots_K8",
                "K": 8,
                "accuracy": 0.725,
                "n_splits": 15
              },
              {
                "method": "dots_K10",
                "K": 10,
                "accuracy": 0.725,
                "n_splits": 15
              },
              {
                "method": "figs_axis_aligned",
                "K": 44,
                "accuracy": 0.75,
                "n_splits": 0
              },
              {
                "method": "random_forest",
                "K": 44,
                "accuracy": 0.75,
                "n_splits": 0
              }
            ],
            "k2_dominates_all_dots": true,
            "dominance_details": [
              {
                "method": "dots_K3",
                "k2_acc": 0.725,
                "other_acc": 0.725,
                "acc_diff": 0.0,
                "k2_dominates": true,
                "dominance_type": "weak"
              },
              {
                "method": "dots_K4",
                "k2_acc": 0.725,
                "other_acc": 0.725,
                "acc_diff": 0.0,
                "k2_dominates": true,
                "dominance_type": "weak"
              },
              {
                "method": "dots_K5",
                "k2_acc": 0.725,
                "other_acc": 0.725,
                "acc_diff": 0.0,
                "k2_dominates": true,
                "dominance_type": "weak"
              },
              {
                "method": "dots_K6",
                "k2_acc": 0.725,
                "other_acc": 0.725,
                "acc_diff": 0.0,
                "k2_dominates": true,
                "dominance_type": "weak"
              },
              {
                "method": "dots_K8",
                "k2_acc": 0.725,
                "other_acc": 0.725,
                "acc_diff": 0.0,
                "k2_dominates": true,
                "dominance_type": "weak"
              },
              {
                "method": "dots_K10",
                "k2_acc": 0.725,
                "other_acc": 0.725,
                "acc_diff": 0.0,
                "k2_dominates": true,
                "dominance_type": "weak"
              }
            ],
            "interpretation": "K=2 weakly Pareto-dominates all higher DOTS K values (identical accuracy, fewer concepts). The Pareto frontier is degenerate: no accuracy-interpretability tradeoff exists. K=2 achieves the same accuracy as K=10 with 5x fewer concepts."
          },
          "family6_verdict": {
            "criteria": [
              {
                "id": "SC1",
                "description": "DOTS K=3-6 within 1-2% of RO-FIGS on >=70% datasets",
                "evidence_summary": "On this dataset: DOTS best (K=3-6) = 0.725, FIGS oblique = 0.775, gap = 0.050 (5.0%). Gap exceeds 2% threshold (5.0%). Single dataset cannot assess 70% threshold.",
                "statistical_values": {
                  "dots_best_acc": 0.725,
                  "figs_oblique_acc": 0.775,
                  "accuracy_gap": 0.05,
                  "within_2pct": false
                },
                "verdict": "NOT_MET"
              },
              {
                "id": "SC2",
                "description": "Substantially fewer unique directions than RO-FIGS",
                "evidence_summary": "DOTS K=2 uses 2 directions vs FIGS oblique's up to 44 (ratio: 0.05). DOTS K=6 uses 6 directions (ratio: 0.14). DOTS achieves 22x to 7x fewer directions — clearly substantial.",
                "statistical_values": {
                  "figs_oblique_max_dirs": 44,
                  "dots_k2_dirs": 2,
                  "dots_k6_dirs": 6,
                  "reduction_ratio_k2": 0.0455,
                  "reduction_ratio_k6": 0.1364
                },
                "verdict": "MET"
              },
              {
                "id": "SC3",
                "description": "Dictionary stability cosine similarity > 0.8",
                "evidence_summary": "K=3: 0.765, K=5: 0.729, mean: 0.747. Below 0.8 threshold but far above null (0.121). Z-score: 7.0. Directions are highly non-random but below the ambitious 0.8 target.",
                "statistical_values": {
                  "k3_cosine": 0.765095,
                  "k5_cosine": 0.728881,
                  "mean_cosine": 0.746988,
                  "threshold": 0.8,
                  "above_threshold": false,
                  "z_score_vs_null": 6.9968
                },
                "verdict": "PARTIALLY_MET"
              },
              {
                "id": "SC4",
                "description": "Clear Pareto frontier with sweet spot at K=4-6",
                "evidence_summary": "K-sweep is perfectly flat (range=0.0000). No accuracy-interpretability tradeoff exists. K=2 weakly Pareto-dominates all higher K. The 'sweet spot' is K=2, not K=4-6 as predicted.",
                "statistical_values": {
                  "k_sweep_range": 0.0,
                  "k_sweep_flat": true,
                  "k2_dominates": true
                },
                "verdict": "NOT_MET"
              },
              {
                "id": "DC1",
                "description": ">3% accuracy loss vs baselines on most datasets",
                "evidence_summary": "DOTS vs FIGS-AA: gap=2.5%. DOTS vs FIGS-oblique: gap=5.0%. The 5% gap vs oblique exceeds the 3% disconfirmation threshold. However, DOTS vs axis-aligned gap is only 2.5% (within threshold). Single dataset prevents assessing 'most datasets'.",
                "statistical_values": {
                  "gap_vs_figs_aa": 0.025,
                  "gap_vs_figs_oblique": 0.05,
                  "exceeds_3pct_aa": false,
                  "exceeds_3pct_oblique": true
                },
                "verdict": "PARTIALLY_TRIGGERED"
              },
              {
                "id": "DC2",
                "description": "Unstable dictionary directions (low cosine similarity)",
                "evidence_summary": "Mean stability: 0.747 (z=7.0 vs null). Directions are highly stable — well above random chance. Disconfirmation NOT triggered.",
                "statistical_values": {
                  "mean_stability": 0.746988,
                  "z_score": 6.9968,
                  "below_0_5": false
                },
                "verdict": "NOT_TRIGGERED"
              }
            ],
            "overall_verdict": "PARTIALLY_SUPPORTED",
            "verdict_justification": "The DOTS hypothesis receives mixed support. SC2 (fewer directions) is clearly met: DOTS uses 2-6 directions vs 44 for unconstrained FIGS. SC3 (stability) is partially met: cosine similarity of 0.75 is far above random (z>6, p<1e-10) but below the 0.8 threshold. SC1 (within 2% of RO-FIGS) is NOT met: the 5% gap exceeds the threshold. SC4 (Pareto sweet spot) is NOT met: the K-sweep is perfectly flat, meaning K=2 dominates rather than K=4-6. DC1 is partially triggered (5% gap vs oblique FIGS). DC2 is NOT triggered (directions are highly stable). The flat K-sweep is scientifically interesting — it suggests the dictionary constraint is 'free' in terms of accuracy — but the overall accuracy gap vs stronger baselines limits the practical claim. Single-dataset evaluation prevents generalizability claims.",
            "summary_counts": {
              "met": 1,
              "partially_met": 2,
              "not_met": 2,
              "triggered": 1
            },
            "limitations": [
              "Single dataset (OpenML-797) — cannot assess generalizability",
              "Per-example predictions only available for dots_K5 vs figs_axis_aligned",
              "Small test set (n=40) limits statistical power for McNemar tests",
              "DOTS predicts majority class for all examples (predict_method='1' for all)",
              "No AUROC per-example data available for bootstrap",
              "K-sweep flatness may be an artifact of the majority-class prediction pattern"
            ],
            "future_work": [
              "Evaluate on multiple diverse datasets to test generalizability",
              "Investigate why all DOTS K values produce identical predictions",
              "Compare against stronger oblique tree baselines (e.g., CART-oblique)",
              "Test with larger sample sizes to improve statistical power",
              "Store per-example predictions for all methods to enable full McNemar analysis",
              "Investigate whether PCA initialization dominates dictionary learning"
            ]
          }
        }
      },
      "dataset": "imodels/tabular-benchmark-797-classification",
      "split": "train",
      "predict_baseline": "1",
      "predict_method": "1",
      "method": "dots_K5",
      "eval_correct_method": 1,
      "eval_correct_baseline": 1,
      "eval_agree": 1
    },
    {
      "input": "Classify the following tabular data sample:\n  F1R: 55.0406\n  F1S: 75.0266\n  F2R: 65.0128\n  F2S: 71.1990\n  F3R: 69.4850\n  F3S: 66.4147\n  F4R: 73.1449\n  F4S: 74.7500\n  F5R: 63.8450\n  F5S: 47.6606\n  F6R: 72.8461\n  F6S: 71.1422\n  F7R: 69.6858\n  F7S: 67.3014\n  F8R: 47.5818\n  F8S: 56.3173\n  F9R: 76.6928\n  F9S: 70.3933\n  F10R: 70.8567\n  F10S: 48.5733\n  F11R: 77.5861\n  F11S: 59.0773\n  F12R: 68.6536\n  F12S: 71.7236\n  F13R: 61.3199\n  F13S: 60.2484\n  F14R: 66.8094\n  F14S: 67.2172\n  F15R: 58.3083\n  F15S: 69.9283\n  F16R: 68.4924\n  F16S: 48.7263\n  F17R: 40.4029\n  F17S: 63.2953\n  F18R: 48.5840\n  F18S: 71.8782\n  F19R: 48.4719\n  F19S: 70.1526\n  F20R: 63.4131\n  F20S: 70.8567\n  F21R: 72.5930\n  F21S: 78.6215\n  F22R: 57.5543\n  F22S: 61.7349",
      "output": "0",
      "context": {
        "features": {
          "F1R": 55.040603,
          "F1S": 75.026624,
          "F2R": 65.012768,
          "F2S": 71.199008,
          "F3R": 69.484965,
          "F3S": 66.414715,
          "F4R": 73.144932,
          "F4S": 74.749982,
          "F5R": 63.844958,
          "F5S": 47.660637,
          "F6R": 72.84605,
          "F6S": 71.142237,
          "F7R": 69.685788,
          "F7S": 67.301352,
          "F8R": 47.581789,
          "F8S": 56.317329,
          "F9R": 76.692806,
          "F9S": 70.393342,
          "F10R": 70.856711,
          "F10S": 48.573269,
          "F11R": 77.586105,
          "F11S": 59.077339,
          "F12R": 68.653648,
          "F12S": 71.723587,
          "F13R": 61.319928,
          "F13S": 60.248435,
          "F14R": 66.80939,
          "F14S": 67.217242,
          "F15R": 58.308323,
          "F15S": 69.928279,
          "F16R": 68.492442,
          "F16S": 48.726294,
          "F17R": 40.402903,
          "F17S": 63.295277,
          "F18R": 48.584012,
          "F18S": 71.878175,
          "F19R": 48.471934,
          "F19S": 70.152586,
          "F20R": 63.41311,
          "F20S": 70.856657,
          "F21R": 72.593045,
          "F21S": 78.62149,
          "F22R": 57.554272,
          "F22S": 61.734926
        },
        "n_features": 44,
        "task_type": "binary_classification",
        "dataset_source": "OpenML-797 benchmark suite",
        "feature_type": "numeric",
        "preprocessing": "none_needed_already_numeric"
      },
      "dataset": "imodels/tabular-benchmark-797-classification",
      "split": "train",
      "predict_baseline": "1",
      "predict_method": "1",
      "method": "dots_K5",
      "eval_correct_method": 0,
      "eval_correct_baseline": 0,
      "eval_agree": 1
    },
    {
      "input": "Classify the following tabular data sample:\n  F1R: 63.5548\n  F1S: 52.9832\n  F2R: 60.0778\n  F2S: 60.4591\n  F3R: 44.8623\n  F3S: 59.5678\n  F4R: 74.5612\n  F4S: 80.6465\n  F5R: 61.8002\n  F5S: 62.5087\n  F6R: 76.9168\n  F6S: 78.1991\n  F7R: 76.4126\n  F7S: 64.5148\n  F8R: 58.7545\n  F8S: 58.3087\n  F9R: 35.8513\n  F9S: 65.7192\n  F10R: 71.6888\n  F10S: 65.3054\n  F11R: 79.2821\n  F11S: 79.1235\n  F12R: 71.6487\n  F12S: 75.2248\n  F13R: 31.5327\n  F13S: 19.5726\n  F14R: 44.6842\n  F14S: 26.4458\n  F15R: 61.9523\n  F15S: 59.4719\n  F16R: 72.5759\n  F16S: 71.8393\n  F17R: 58.1855\n  F17S: 64.5165\n  F18R: 59.7496\n  F18S: 61.3222\n  F19R: 75.9075\n  F19S: 72.1122\n  F20R: 72.3178\n  F20S: 63.4827\n  F21R: 75.8465\n  F21S: 66.5678\n  F22R: 68.8849\n  F22S: 30.7395",
      "output": "1",
      "context": {
        "features": {
          "F1R": 63.554782,
          "F1S": 52.983165,
          "F2R": 60.077782,
          "F2S": 60.459062,
          "F3R": 44.862288,
          "F3S": 59.567838,
          "F4R": 74.561229,
          "F4S": 80.646485,
          "F5R": 61.800248,
          "F5S": 62.50865,
          "F6R": 76.91681,
          "F6S": 78.199076,
          "F7R": 76.412578,
          "F7S": 64.514819,
          "F8R": 58.754494,
          "F8S": 58.308706,
          "F9R": 35.851271,
          "F9S": 65.71916,
          "F10R": 71.688791,
          "F10S": 65.305414,
          "F11R": 79.282058,
          "F11S": 79.123526,
          "F12R": 71.648667,
          "F12S": 75.224795,
          "F13R": 31.532748,
          "F13S": 19.572599,
          "F14R": 44.684151,
          "F14S": 26.44583,
          "F15R": 61.952338,
          "F15S": 59.471863,
          "F16R": 72.575938,
          "F16S": 71.839251,
          "F17R": 58.185494,
          "F17S": 64.516538,
          "F18R": 59.749603,
          "F18S": 61.322201,
          "F19R": 75.907469,
          "F19S": 72.112163,
          "F20R": 72.317805,
          "F20S": 63.482745,
          "F21R": 75.846486,
          "F21S": 66.567848,
          "F22R": 68.884922,
          "F22S": 30.739544
        },
        "n_features": 44,
        "task_type": "binary_classification",
        "dataset_source": "OpenML-797 benchmark suite",
        "feature_type": "numeric",
        "preprocessing": "none_needed_already_numeric"
      },
      "dataset": "imodels/tabular-benchmark-797-classification",
      "split": "test",
      "predict_baseline": "1",
      "predict_method": "1",
      "method": "dots_K5",
      "eval_correct_method": 1,
      "eval_correct_baseline": 1,
      "eval_agree": 1
    }
  ]
}